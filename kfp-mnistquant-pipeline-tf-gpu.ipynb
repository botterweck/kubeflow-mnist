{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea5a454-49f8-4a4c-878e-5915c8624aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Base Image\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.dsl import Input, Output\n",
    "from kfp.dsl import Dataset, Artifact\n",
    "from kfp.dsl import Model, Metrics, ClassificationMetrics\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "BASE_IMAGE = 'nvcr.io/nvidia/tensorflow:25.01-tf2-py3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65d174d-5fb2-4784-911b-016ee3962406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE,\n",
    ")\n",
    "def load_data(\n",
    "    x_train_pickle: Output[Dataset],\n",
    "    y_train_pickle: Output[Dataset],\n",
    "    x_test_pickle: Output[Dataset],\n",
    "    y_test_pickle: Output[Dataset],\n",
    "):\n",
    "    # import dataset\n",
    "    from keras.datasets import mnist\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "\n",
    "    # load dataset\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # count the number of unique train labels\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    print(\"Train labels: \", dict(zip(unique, counts)))\n",
    "\n",
    "    # count the number of unique test labels\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "    print(\"\\nTest labels: \", dict(zip(unique, counts)))\n",
    "\n",
    "    with open(x_train_pickle.path, \"wb\") as file:\n",
    "        pickle.dump(x_train, file)\n",
    "\n",
    "    with open(y_train_pickle.path, \"wb\") as file:\n",
    "        pickle.dump(y_train, file)\n",
    "\n",
    "    with open(x_test_pickle.path, \"wb\") as file:\n",
    "        pickle.dump(x_test, file)\n",
    "\n",
    "    with open(y_test_pickle.path, \"wb\") as file:\n",
    "        pickle.dump(y_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7a2631-3086-417d-8381-915ee7eae51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data \n",
    "\n",
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def preprocess_data(\n",
    "    x_train_pickle: Input[Dataset],\n",
    "    y_train_pickle: Input[Dataset],\n",
    "    x_test_pickle: Input[Dataset],\n",
    "    y_test_pickle: Input[Dataset],\n",
    "    x_train_prep: Output[Dataset], # Output preprocessed training data (needed for quantization)\n",
    "    y_train_prep: Output[Dataset],\n",
    "    x_test_prep: Output[Dataset],\n",
    "    y_test_prep: Output[Dataset],\n",
    ") -> NamedTuple(\"outputs\", input_size=int, num_labels=int):\n",
    "\n",
    "    from keras.utils import to_categorical\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from typing import NamedTuple\n",
    "\n",
    "    with open(x_train_pickle.path, \"rb\") as file:\n",
    "        x_train = pickle.load(file)\n",
    "\n",
    "    with open(y_train_pickle.path, \"rb\") as file:\n",
    "        y_train = pickle.load(file)\n",
    "\n",
    "    with open(x_test_pickle.path, \"rb\") as file:\n",
    "        x_test = pickle.load(file)\n",
    "\n",
    "    with open(y_test_pickle.path, \"rb\") as file:\n",
    "        y_test = pickle.load(file)\n",
    "\n",
    "    num_labels = len(np.unique(y_train))\n",
    "\n",
    "    # Reshape and normalize training data (needed for quantization calibration)\n",
    "    image_size = x_train.shape[1]\n",
    "    input_size = image_size * image_size\n",
    "    x_train_processed = np.reshape(x_train, [-1, input_size])\n",
    "    x_train_processed = x_train_processed.astype(\"float32\") / 255\n",
    "\n",
    "    # Reshape and normalize test data\n",
    "    x_test_processed = np.reshape(x_test, [-1, input_size])\n",
    "    x_test_processed = x_test_processed.astype(\"float32\") / 255\n",
    "\n",
    "    # One-hot encode labels\n",
    "    y_train_processed = to_categorical(y_train)\n",
    "    y_test_processed = to_categorical(y_test)\n",
    "\n",
    "    # Save processed data\n",
    "    with open(x_train_prep.path, \"wb\") as file:\n",
    "        pickle.dump(x_train_processed, file)\n",
    "\n",
    "    with open(y_train_prep.path, \"wb\") as file:\n",
    "        pickle.dump(y_train_processed, file)\n",
    "\n",
    "    with open(x_test_prep.path, \"wb\") as file:\n",
    "        pickle.dump(x_test_processed, file)\n",
    "\n",
    "    with open(y_test_prep.path, \"wb\") as file:\n",
    "        pickle.dump(y_test_processed, file)\n",
    "\n",
    "    outputs = NamedTuple(\"outputs\", input_size=int, num_labels=int)\n",
    "    return outputs(input_size, num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca53b65c-fb23-4c0f-a096-d9e1d6d8b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def train(\n",
    "    input_size: int,\n",
    "    num_labels: int,\n",
    "    epochs: int,\n",
    "    x_train_prep: Input[Dataset], # Changed input name for clarity\n",
    "    y_train_prep: Input[Dataset], # Changed input name for clarity\n",
    "    model_artifact: Output[Model],\n",
    "    log: Output[Artifact],\n",
    "):\n",
    "    from keras.callbacks import TensorBoard\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, Dropout\n",
    "    import pickle\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if not gpus:\n",
    "        print(\"TensorFlow CANNOT see any GPUs. GPU acceleration is NOT possible.\")\n",
    "    else:\n",
    "        print(f\"TensorFlow found {len(gpus)} GPU(s): {gpus}\")\n",
    "\n",
    "    batch_size = 128\n",
    "    hidden_units = 256\n",
    "    dropout = 0.45\n",
    "\n",
    "    with open(x_train_prep.path, \"rb\") as file: # Changed path name\n",
    "        x_train = pickle.load(file)\n",
    "\n",
    "    with open(y_train_prep.path, \"rb\") as file: # Changed path name\n",
    "        y_train = pickle.load(file)\n",
    "\n",
    "\n",
    "    log_dir = f\"{log.path}/logs/fit/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=input_size))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(hidden_units))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "    # Save the Keras model in the native format\n",
    "    os.makedirs(model_artifact.path, exist_ok=True)\n",
    "    # Keras model needs to be saved in a sub-directory for TFLite conversion later\n",
    "    model_dir_path = os.path.join(model_artifact.path, \"fp32_model\")\n",
    "    os.makedirs(model_dir_path, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir_path, \"model.keras\") # Use .keras extension\n",
    "    model.save(model_path)\n",
    "    print(f\"[train] Keras model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5a18da-1bf6-4bef-b373-680333f747ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize the model\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE,\n",
    ")\n",
    "def quantize_model(\n",
    "    keras_model_input: Input[Model], # Input is the directory containing the Keras model\n",
    "    x_train_prep: Input[Dataset], # Need training data for calibration\n",
    "    quantized_model_output: Output[Model], # Output will be the .tflite file\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import os\n",
    "\n",
    "    # Load the FP32 Keras model\n",
    "    # model.save() creates a directory, find the .keras file inside\n",
    "    model_dir_path = os.path.join(keras_model_input.path, \"fp32_model\")\n",
    "    keras_model_path = os.path.join(model_dir_path, \"model.keras\")\n",
    "    print(f\"[quantize] Loading Keras model from: {keras_model_path}\")\n",
    "    model = tf.keras.models.load_model(keras_model_path)\n",
    "\n",
    "    # Load representative dataset (calibration data)\n",
    "    print(f\"[quantize] Loading representative data from: {x_train_prep.path}\")\n",
    "    with open(x_train_prep.path, \"rb\") as file:\n",
    "        x_train = pickle.load(file)\n",
    "\n",
    "    # Create a representative dataset generator\n",
    "    # Use a subset for faster calibration (e.g., 100 samples)\n",
    "    def representative_data_gen():\n",
    "        num_samples = min(100, len(x_train))\n",
    "        for i in range(num_samples):\n",
    "            # Get sample input data as a numpy array\n",
    "            # Input shape needs to match model input: add batch dimension\n",
    "            yield [np.expand_dims(x_train[i], axis=0).astype(np.float32)]\n",
    "\n",
    "    print(\"[quantize] Starting TFLite conversion with INT8 quantization...\")\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    # Ensure that if any ops can't be quantized, the converter throws an error\n",
    "    # Ensure ops are compatible with integer-only inference\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    # Set input and output tensors to int8 (or uint8)\n",
    "    # MNIST inputs are 0-255 originally, normalized to 0-1.\n",
    "    # int8 quantization typically maps float range [-a, a] to int [-128, 127].\n",
    "    # uint8 quantization typically maps float range [0, b] to uint [0, 255].\n",
    "    # Let's try int8 as it's common, TF Lite handles the scaling.\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "\n",
    "    tflite_model_quant = converter.convert()\n",
    "    print(\"[quantize] TFLite conversion finished.\")\n",
    "\n",
    "    # Save the quantized model\n",
    "    # The output artifact path is a directory, save the file inside it\n",
    "    os.makedirs(quantized_model_output.path, exist_ok=True)\n",
    "    tflite_model_path = os.path.join(quantized_model_output.path, 'quantized_model.tflite')\n",
    "    with open(tflite_model_path, 'wb') as f:\n",
    "        f.write(tflite_model_quant)\n",
    "    print(f\"[quantize] Quantized TFLite model saved to: {tflite_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6aa55cf-e1c2-4ebb-95c6-5b7e31639561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fp32 model\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=[\"scikit-learn\"],\n",
    ")\n",
    "def evaluate_fp32_model(\n",
    "    model_artifact: Input[Model], # Input is the directory containing the Keras model\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    scalar_metrics: Output[Metrics],\n",
    "    x_test_prep: Input[Dataset], # Changed input name for clarity\n",
    "    y_test_prep: Input[Dataset], # Changed input name for clarity\n",
    "):\n",
    "    from keras.models import load_model\n",
    "    from keras.metrics import Precision # Note: Keras Precision might not be ideal here\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    # Load the Keras model\n",
    "    model_dir_path = os.path.join(model_artifact.path, \"fp32_model\")\n",
    "    model_path = os.path.join(model_dir_path, \"model.keras\")\n",
    "    print(f\"[evaluate_fp32] loading model from {model_path}\")\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    with open(x_test_prep.path, \"rb\") as file: # Changed path name\n",
    "        x_test = pickle.load(file)\n",
    "\n",
    "    with open(y_test_prep.path, \"rb\") as file: # Changed path name\n",
    "        y_test = pickle.load(file) # y_test is one-hot encoded\n",
    "\n",
    "    # Evaluate using Keras model.evaluate\n",
    "    loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
    "    print(f\"[evaluate_fp32] Keras Evaluation - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Get predictions for confusion matrix and other metrics\n",
    "    y_pred_proba = model.predict(x_test, batch_size=batch_size)\n",
    "    y_pred_labels = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics using sklearn\n",
    "    # Use macro average for precision as it's multi-class\n",
    "    precision = precision_score(y_true_labels, y_pred_labels, average='macro', zero_division=0)\n",
    "    print(f\"[evaluate_fp32] Sklearn Metrics - Accuracy: {acc:.4f}, Precision (macro): {precision:.4f}\")\n",
    "\n",
    "    # Log metrics\n",
    "    scalar_metrics.log_metric(\"fp32_accuracy\", float(acc))\n",
    "    scalar_metrics.log_metric(\"fp32_loss\", float(loss))\n",
    "    scalar_metrics.log_metric(\"fp32_precision_macro\", float(precision))\n",
    "\n",
    "    metrics.log_confusion_matrix(\n",
    "        [str(i) for i in range(10)], # Class names '0' through '9'\n",
    "        confusion_matrix(y_true_labels, y_pred_labels).tolist(), # Convert np array to list\n",
    "    )\n",
    "    print(\"[evaluate_fp32] Metrics logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6228ce74-3781-4903-89ef-5715dd35b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate quantized model\n",
    "\n",
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=[\"scikit-learn\"],\n",
    ")\n",
    "def evaluate_quantized_model(\n",
    "    quantized_model_artifact: Input[Model], # Input is the directory containing .tflite\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    scalar_metrics: Output[Metrics],\n",
    "    x_test_prep: Input[Dataset],\n",
    "    y_test_prep: Input[Dataset],\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import os\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "    # Load the TFLite model and allocate tensors\n",
    "    tflite_model_path = os.path.join(quantized_model_artifact.path, 'quantized_model.tflite')\n",
    "    print(f\"[evaluate_quantized] Loading TFLite model from: {tflite_model_path}\")\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensor details\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    input_dtype = input_details['dtype']\n",
    "    output_dtype = output_details['dtype']\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "    print(f\"[evaluate_quantized] Input Details: {input_details}\")\n",
    "    print(f\"[evaluate_quantized] Output Details: {output_details}\")\n",
    "\n",
    "    # Load test data\n",
    "    print(f\"[evaluate_quantized] Loading test data...\")\n",
    "    with open(x_test_prep.path, \"rb\") as file:\n",
    "        x_test_float = pickle.load(file) # Load original float32 data\n",
    "\n",
    "    with open(y_test_prep.path, \"rb\") as file:\n",
    "        y_test_one_hot = pickle.load(file)\n",
    "    y_true_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "    print(f\"[evaluate_quantized] Quantizing input data to {input_dtype}...\")\n",
    "    # Quantize input data according to input tensor details\n",
    "    # Formula: int_value = float_value / scale + zero_point\n",
    "    x_test_quantized = (x_test_float / input_scale) + input_zero_point\n",
    "    x_test_quantized = x_test_quantized.astype(input_dtype)\n",
    "    print(f\"[evaluate_quantized] Input data shape: {x_test_quantized.shape}, dtype: {x_test_quantized.dtype}\")\n",
    "\n",
    "\n",
    "    # Run inference\n",
    "    print(f\"[evaluate_quantized] Running inference on {len(x_test_quantized)} samples...\")\n",
    "    y_pred_quantized_list = []\n",
    "    for i in range(len(x_test_quantized)):\n",
    "        interpreter.set_tensor(input_details['index'], np.expand_dims(x_test_quantized[i], axis=0))\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details['index'])\n",
    "        y_pred_quantized_list.append(output_data[0]) # Remove batch dim\n",
    "\n",
    "    y_pred_quantized = np.array(y_pred_quantized_list)\n",
    "    print(f\"[evaluate_quantized] Inference complete. Output shape: {y_pred_quantized.shape}, dtype: {y_pred_quantized.dtype}\")\n",
    "\n",
    "    # Dequantize output predictions to calculate loss/metrics easily\n",
    "    # Formula: float_value = (int_value - zero_point) * scale\n",
    "    y_pred_float = (y_pred_quantized.astype(np.float32) - output_zero_point) * output_scale\n",
    "    print(f\"[evaluate_quantized] Dequantized output shape: {y_pred_float.shape}, dtype: {y_pred_float.dtype}\")\n",
    "\n",
    "    # Get predicted labels\n",
    "    y_pred_labels = np.argmax(y_pred_float, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    # Use macro average for precision as it's multi-class\n",
    "    precision = precision_score(y_true_labels, y_pred_labels, average='macro', zero_division=0)\n",
    "    # Calculate categorical cross-entropy loss (requires probabilities)\n",
    "    # Softmax the dequantized outputs\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "    y_pred_proba = softmax(y_pred_float)\n",
    "    # Compute loss - use stable version\n",
    "    N = y_pred_proba.shape[0]\n",
    "    log_likelihood = -np.log(y_pred_proba[range(N), y_true_labels] + 1e-9) # Add epsilon for stability\n",
    "    loss = np.sum(log_likelihood) / N\n",
    "\n",
    "    print(f\"[evaluate_quantized] Metrics - Accuracy: {accuracy:.4f}, Precision (macro): {precision:.4f}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # Log metrics\n",
    "    scalar_metrics.log_metric(\"quantized_int8_accuracy\", float(accuracy))\n",
    "    scalar_metrics.log_metric(\"quantized_int8_loss\", float(loss))\n",
    "    scalar_metrics.log_metric(\"quantized_int8_precision_macro\", float(precision))\n",
    "\n",
    "    metrics.log_confusion_matrix(\n",
    "        [str(i) for i in range(10)], # Class names '0' through '9'\n",
    "        confusion_matrix(y_true_labels, y_pred_labels).tolist(), # Convert np array to list\n",
    "    )\n",
    "    print(\"[evaluate_quantized] Metrics logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4477e3a8-58ae-4530-84b0-a5ec57a432ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=[\"scikit-learn\"],\n",
    ")\n",
    "def evaluate_quantized_model(\n",
    "    quantized_model_artifact: Input[Model], # Input is the directory containing .tflite\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    scalar_metrics: Output[Metrics],\n",
    "    x_test_prep: Input[Dataset],\n",
    "    y_test_prep: Input[Dataset],\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import os\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "    # Load the TFLite model and allocate tensors\n",
    "    tflite_model_path = os.path.join(quantized_model_artifact.path, 'quantized_model.tflite')\n",
    "    print(f\"[evaluate_quantized] Loading TFLite model from: {tflite_model_path}\")\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensor details\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    input_dtype = input_details['dtype']\n",
    "    output_dtype = output_details['dtype']\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "    print(f\"[evaluate_quantized] Input Details: {input_details}\")\n",
    "    print(f\"[evaluate_quantized] Output Details: {output_details}\")\n",
    "\n",
    "    # Load test data\n",
    "    print(f\"[evaluate_quantized] Loading test data...\")\n",
    "    with open(x_test_prep.path, \"rb\") as file:\n",
    "        x_test_float = pickle.load(file) # Load original float32 data\n",
    "\n",
    "    with open(y_test_prep.path, \"rb\") as file:\n",
    "        y_test_one_hot = pickle.load(file)\n",
    "    y_true_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "    print(f\"[evaluate_quantized] Quantizing input data to {input_dtype}...\")\n",
    "    # Quantize input data according to input tensor details\n",
    "    # Formula: int_value = float_value / scale + zero_point\n",
    "    x_test_quantized = (x_test_float / input_scale) + input_zero_point\n",
    "    x_test_quantized = x_test_quantized.astype(input_dtype)\n",
    "    print(f\"[evaluate_quantized] Input data shape: {x_test_quantized.shape}, dtype: {x_test_quantized.dtype}\")\n",
    "\n",
    "\n",
    "    # Run inference\n",
    "    print(f\"[evaluate_quantized] Running inference on {len(x_test_quantized)} samples...\")\n",
    "    y_pred_quantized_list = []\n",
    "    for i in range(len(x_test_quantized)):\n",
    "        interpreter.set_tensor(input_details['index'], np.expand_dims(x_test_quantized[i], axis=0))\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details['index'])\n",
    "        y_pred_quantized_list.append(output_data[0]) # Remove batch dim\n",
    "\n",
    "    y_pred_quantized = np.array(y_pred_quantized_list)\n",
    "    print(f\"[evaluate_quantized] Inference complete. Output shape: {y_pred_quantized.shape}, dtype: {y_pred_quantized.dtype}\")\n",
    "\n",
    "    # Dequantize output predictions to calculate loss/metrics easily\n",
    "    # Formula: float_value = (int_value - zero_point) * scale\n",
    "    y_pred_float = (y_pred_quantized.astype(np.float32) - output_zero_point) * output_scale\n",
    "    print(f\"[evaluate_quantized] Dequantized output shape: {y_pred_float.shape}, dtype: {y_pred_float.dtype}\")\n",
    "\n",
    "    # Get predicted labels\n",
    "    y_pred_labels = np.argmax(y_pred_float, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    # Use macro average for precision as it's multi-class\n",
    "    precision = precision_score(y_true_labels, y_pred_labels, average='macro', zero_division=0)\n",
    "    # Calculate categorical cross-entropy loss (requires probabilities)\n",
    "    # Softmax the dequantized outputs\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "    y_pred_proba = softmax(y_pred_float)\n",
    "    # Compute loss - use stable version\n",
    "    N = y_pred_proba.shape[0]\n",
    "    log_likelihood = -np.log(y_pred_proba[range(N), y_true_labels] + 1e-9) # Add epsilon for stability\n",
    "    loss = np.sum(log_likelihood) / N\n",
    "\n",
    "    print(f\"[evaluate_quantized] Metrics - Accuracy: {accuracy:.4f}, Precision (macro): {precision:.4f}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # Log metrics\n",
    "    scalar_metrics.log_metric(\"quantized_int8_accuracy\", float(accuracy))\n",
    "    scalar_metrics.log_metric(\"quantized_int8_loss\", float(loss))\n",
    "    scalar_metrics.log_metric(\"quantized_int8_precision_macro\", float(precision))\n",
    "\n",
    "    metrics.log_confusion_matrix(\n",
    "        [str(i) for i in range(10)], # Class names '0' through '9'\n",
    "        confusion_matrix(y_true_labels, y_pred_labels).tolist(), # Convert np array to list\n",
    "    )\n",
    "    print(\"[evaluate_quantized] Metrics logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070a99c6-6d78-4b28-b9da-2f4425aca8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"mnist-pipeline-tf-gpu-quantized\", # Renamed pipeline\n",
    "    description=\"Loads MNIST, preprocesses, trains, quantizes, and evaluates FP32 and INT8 models.\"\n",
    ")\n",
    "def mnist_pipeline(epochs: int = 20): # Default epochs set\n",
    "    # Load Data\n",
    "    load_data_task = (\n",
    "        load_data()\n",
    "        .set_memory_limit(\"4G\").set_memory_request(\"2G\")\n",
    "        .set_cpu_limit(\"2\").set_cpu_request(\"1\")\n",
    "        .set_display_name(\"Load MNIST Data\")\n",
    "        .set_caching_options(False) # Disable caching temporarily for troubleshooting\n",
    "    )\n",
    "\n",
    "    # Preprocess Data\n",
    "    preprocess_task = (\n",
    "        preprocess_data(\n",
    "            x_train_pickle=load_data_task.outputs[\"x_train_pickle\"],\n",
    "            y_train_pickle=load_data_task.outputs[\"y_train_pickle\"],\n",
    "            x_test_pickle=load_data_task.outputs[\"x_test_pickle\"],\n",
    "            y_test_pickle=load_data_task.outputs[\"y_test_pickle\"],\n",
    "        )\n",
    "        .set_memory_limit(\"4G\").set_memory_request(\"2G\")\n",
    "        .set_cpu_limit(\"1\").set_cpu_request(\"1\")\n",
    "        .set_display_name(\"Preprocess Data\")\n",
    "        .set_caching_options(False) # Disable caching temporarily for troubleshooting\n",
    "    )\n",
    "    preprocess_task.after(load_data_task) # Ensure execution order\n",
    "\n",
    "    # Train FP32 Model\n",
    "    train_task = (\n",
    "        train(\n",
    "            input_size=preprocess_task.outputs[\"input_size\"],\n",
    "            num_labels=preprocess_task.outputs[\"num_labels\"],\n",
    "            epochs=epochs,\n",
    "            x_train_prep=preprocess_task.outputs[\"x_train_prep\"], # Use preprocessed data\n",
    "            y_train_prep=preprocess_task.outputs[\"y_train_prep\"], # Use preprocessed data\n",
    "        )\n",
    "        .set_gpu_limit(1)\n",
    "        # Use the correct node selector syntax if needed, or remove if not required\n",
    "        # .add_node_selector_constraint('nvidia.com/gpu', 'true') # Example if value is 'true'\n",
    "        # .add_node_selector_constraint('nvidia.com/gpu', '<gpu_model_name>') # Example if value is model name\n",
    "        # Or remove if set_gpu_limit is sufficient\n",
    "        .set_memory_limit(\"4G\").set_memory_request(\"2G\") # Increased memory for TF\n",
    "        .set_cpu_limit(\"2\").set_cpu_request(\"1\") # Increased CPU slightly\n",
    "        .set_display_name(\"Train FP32 Model\")\n",
    "        .set_caching_options(False) # Disable caching temporarily for troubleshooting\n",
    "    )\n",
    "    train_task.after(preprocess_task)\n",
    "\n",
    "    # Evaluate FP32 Model\n",
    "    evaluate_fp32_task = (\n",
    "        evaluate_fp32_model( # Renamed function call\n",
    "            model_artifact=train_task.outputs[\"model_artifact\"],\n",
    "            x_test_prep=preprocess_task.outputs[\"x_test_prep\"], # Use preprocessed data\n",
    "            y_test_prep=preprocess_task.outputs[\"y_test_prep\"], # Use preprocessed data\n",
    "        )\n",
    "        .set_memory_limit(\"4G\").set_memory_request(\"2G\")\n",
    "        .set_cpu_limit(\"1\").set_cpu_request(\"1\")\n",
    "        .set_display_name(\"Evaluate FP32 Model\")\n",
    "        .set_caching_options(False) # Disable caching temporarily for troubleshooting\n",
    "    )\n",
    "    evaluate_fp32_task.after(train_task)\n",
    "\n",
    "    # Quantize Model to INT8\n",
    "    quantize_task = (\n",
    "        quantize_model(\n",
    "            keras_model_input=train_task.outputs[\"model_artifact\"],\n",
    "            x_train_prep=preprocess_task.outputs[\"x_train_prep\"], # Use preprocessed train data for calibration\n",
    "        )\n",
    "        .set_memory_limit(\"4G\").set_memory_request(\"2G\") # Quantization can use memory\n",
    "        .set_cpu_limit(\"1\").set_cpu_request(\"1\")\n",
    "        .set_display_name(\"Quantize Model (INT8)\")\n",
    "        .set_caching_options(False) # Disable caching temporarily for troubleshooting\n",
    "    )\n",
    "    quantize_task.after(train_task) # Depends on the trained model\n",
    "\n",
    "    # Evaluate Quantized INT8 Model\n",
    "    evaluate_quantized_task = (\n",
    "        evaluate_quantized_model(\n",
    "            quantized_model_artifact=quantize_task.outputs[\"quantized_model_output\"],\n",
    "            x_test_prep=preprocess_task.outputs[\"x_test_prep\"], # Use preprocessed test data\n",
    "            y_test_prep=preprocess_task.outputs[\"y_test_prep\"], # Use preprocessed test data\n",
    "        )\n",
    "        .set_memory_limit(\"4G\").set_memory_request(\"2G\")\n",
    "        .set_cpu_limit(\"1\").set_cpu_request(\"1\")\n",
    "        .set_display_name(\"Evaluate Quantized INT8 Model\")\n",
    "        .set_caching_options(False) # Disable caching temporarily for troubleshooting\n",
    "    )\n",
    "    # Depends on quantized model and preprocessed data, run after quantization\n",
    "    evaluate_quantized_task.after(quantize_task)\n",
    "    evaluate_quantized_task.after(preprocess_task) # Explicit dependency for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd89793-ed7a-4a4d-95e8-f45ec73544ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/kfp/client/client.py:159: FutureWarning: This client only works with Kubeflow Pipeline v2.0.0-beta.2 and later versions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/ceeeb68d-a201-4e62-b693-c2997177635e\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/f2f7d428-ec37-42d3-84ee-7d9319989667\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline run submitted. Run details: f2f7d428-ec37-42d3-84ee-7d9319989667\n"
     ]
    }
   ],
   "source": [
    "# Run pipeline (\n",
    "client = kfp.Client()\n",
    "\n",
    "# Make sure KFP client points to your Kubeflow endpoint if needed\n",
    "# client = kfp.Client(host='<your-kubeflow-pipelines-url>')\n",
    "\n",
    "run = client.create_run_from_pipeline_func(\n",
    "    mnist_pipeline,\n",
    "    arguments={\"epochs\": 3},\n",
    "    experiment_name=\"mnist_pipeline\",\n",
    ")\n",
    "\n",
    "print(f\"Pipeline run submitted. Run details: {run.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc75e9-b258-40b4-a3b3-fbe57e3b70e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
